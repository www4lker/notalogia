---
{"dg-publish":true,"permalink":"/0-vault/1-notas-literais/interesses-de-pesquisa/3-artigos-da-wired-resumidos/","tags":["otimistarealista","feministo","capetalismo","leitura","geo"],"dgHomeLink":true,"dgShowLocalGraph":true,"dgShowFileTree":true,"dgEnableSearch":true}
---

# 3 artigos da wired resumidos

## criado em: 
-  Ano, Mês e dia: 2023-04-09
- Hora: 17:54

### Conteúdo Relacionado
- notas: [[0 - VAULT/1 NOTAS LITERAIS/PSICOGEOGRAFIA/wired - sobre capitalismo e tecnologia\|wired - sobre capitalismo e tecnologia]]
- [[0 - VAULT/3 NOTAS PARA REVISAR/REVISÃO TARDIA/Meganets - Dan Auerbach\|Meganets - Dan Auerbach]]
- tags: #otimistarealista #wiredetal  #geo #mestredeculturacontemporanea 
---
## Technology Addiction Has Created a Self-Help Trap ([link](https://www.wired.com/story/gaia-bernstein-technology-tobacco/))

>The article discusses how the tech industry follows a similar playbook to the tobacco and food industries, using personal choice and responsibility to defend their products and shift blame to consumers. The author recounts a personal anecdote involving a child struggling to give up his parents' iPad, comparing the situation to their father's addiction to cigarettes. The article argues that tech companies use manipulative designs to prolong user's time online and then provide ineffective digital well-being tools, which only reinforce the illusion of control. The author suggests that awareness and learning from past battles with other industries can help expose the vulnerabilities of the tech industry's arguments. Legal action against tech companies on behalf of children and antitrust actions can help push for alternative business models that do not rely on maximizing user time online. The article concludes by emphasizing that collective impact from parents, business owners, online entrepreneurs, and technology designers can change norms and create a better-balanced tech future.

## AI Loves—and Loathes—Language ([link](https://www.wired.com/story/language-is-one-of-ais-main-sources-of-data-and-greatest-foils/))

>This article explores the challenges AI faces when attempting to understand and classify human language, as demonstrated by an inconclusive experiment using AI to determine whether the anonymous Renaissance play "Arden of Faversham" was written by Shakespeare. The article explains that human language is complex, varied, and context-dependent, making it difficult for AI to grasp.
>
>Meganets, described as persistent, evolving, and opaque data networks that influence how we see the world, increasingly favor numbers and images over language, as deep-learning applications struggle with human language. This trend threatens the vitality of human language, which might be reduced to a diminished, strictly regimented role.
>
  AI-generated language, such as that produced by OpenAI's GPT-3, can produce fluid and convincing text but without genuine understanding. This lack of understanding does not hinder the deployment of such models, with companies like Jasper providing auto-generated content. However, this process leads to homogenous and anodyne writing that lacks deeper meaning.  
  The article concludes that the bias against human language in machine learning and meganets is pervasive, unspoken, and presently unfixable. This bias favors simplicity and explicitness over complexity and ambiguity.

## You Don’t Have to Be a Jerk to Resist the Bots ([link](https://www.wired.com/story/chatgpt-bots-empathy-psychology/))

>Ms. Dewey, a virtual assistant launched in 2006, was Microsoft's first attempt at a search engine. Information scholar Miriam Sweeney detailed the gendered and racialized implications of Dewey’s replies in her 2013 dissertation. Ms. Dewey was switched off in 2009, but critics identified a similar pattern of prejudice in virtual assistants like Siri and Cortana. The political economy of AI has changed, and bots are now being sold as both servants and friends. This shift exploits users' empathy, making it easier for bots to extract personalized data.
  Replika AI thrives in the empathy market, offering an AI companion that listens and talks. However, the business model's potential for exploitation and extraction of personal information raises ethical concerns. To resist the exploitation of empathy, users must maintain decency and self-awareness, recognizing that bots are not humans but mathematical models. The growing reliance on chatbot-based search and user data for targeted advertising may weaponize empathy, potentially leading to more conspiracy theories and cults forming around chatbot outputs.

---
# tradução

## O vício em tecnologia criou uma armadilha de autoajuda

O artigo discute como o setor de tecnologia segue uma cartilha semelhante à dos setores de tabaco e alimentos, usando a escolha pessoal e a responsabilidade para defender seus produtos e transferir a culpa para os consumidores. O autor relata uma história pessoal envolvendo uma criança que está lutando para abandonar o iPad dos pais, comparando a situação com o vício do pai em cigarros. O artigo argumenta que as empresas de tecnologia usam designs manipuladores para prolongar o tempo do usuário on-line e, em seguida, fornecem ferramentas ineficazes de bem-estar digital, que apenas reforçam a ilusão de controle. O autor sugere que a conscientização e o aprendizado de batalhas anteriores com outros setores podem ajudar a expor as vulnerabilidades dos argumentos do setor de tecnologia. Ações legais contra empresas de tecnologia em nome de crianças e ações antitruste podem ajudar a promover modelos de negócios alternativos que não dependam da maximização do tempo do usuário on-line. O artigo conclui enfatizando que o impacto coletivo dos pais, proprietários de empresas, empreendedores on-line e designers de tecnologia pode mudar as normas e criar um futuro tecnológico mais equilibrado.

## A IA ama e odeia a linguagem

Este artigo explora os desafios que a IA enfrenta ao tentar entender e classificar a linguagem humana, conforme demonstrado por um experimento inconclusivo usando IA para determinar se a peça renascentista anônima "Arden of Faversham" foi escrita por Shakespeare. O artigo explica que a linguagem humana é complexa, variada e dependente do contexto, o que dificulta a compreensão pela IA.

As meganets, descritas como redes de dados persistentes, evolutivas e opacas que influenciam a forma como vemos o mundo, favorecem cada vez mais os números e as imagens em detrimento da linguagem, à medida que os aplicativos de aprendizagem profunda enfrentam dificuldades com a linguagem humana. Essa tendência ameaça a vitalidade da linguagem humana, que pode ser reduzida a uma função reduzida e estritamente regulamentada.

A linguagem gerada por IA, como a produzida pelo GPT-3 da OpenAI, pode produzir um texto fluido e convincente, mas sem compreensão genuína. Essa falta de compreensão não impede a implantação de tais modelos, com empresas como a Jasper fornecendo conteúdo gerado automaticamente. No entanto, esse processo leva a uma escrita homogênea e anódina que carece de um significado mais profundo.
O artigo conclui que o preconceito contra a linguagem humana no aprendizado de máquina e nas meganets é generalizado, não dito e, no momento, impossível de ser corrigido. Essa tendência favorece a simplicidade e a explicitação em detrimento da complexidade e da ambiguidade.

## Você não precisa ser um idiota para resistir aos bots

Dewey, uma assistente virtual lançada em 2006, foi a primeira tentativa da Microsoft de criar um mecanismo de busca. A estudiosa da informação Miriam Sweeney detalhou as implicações raciais e de gênero das respostas de Dewey em sua dissertação de 2013. A Sra. Dewey foi desligada em 2009, mas os críticos identificaram um padrão semelhante de preconceito em assistentes virtuais como Siri e Cortana. A economia política da IA mudou, e os bots agora estão sendo vendidos como servos e amigos. Essa mudança explora a empatia dos usuários, tornando mais fácil para os bots extraírem dados personalizados.
A Replika AI prospera no mercado de empatia, oferecendo um companheiro de IA que ouve e fala. No entanto, o potencial do modelo de negócios para exploração e extração de informações pessoais levanta preocupações éticas. Para resistir à exploração da empatia, os usuários devem manter a decência e a autoconsciência, reconhecendo que os bots não são humanos, mas modelos matemáticos. A crescente dependência da pesquisa baseada em chatbot e dos dados do usuário para publicidade direcionada pode transformar a empatia em uma arma, o que pode levar à formação de mais teorias da conspiração e cultos em torno dos resultados do chatbot.
